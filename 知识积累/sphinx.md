---
title: 搜索引擎sphinx
date: 2017-10-20 11:44:02
tags: 搜索引擎,sphinx
---

> ### sphin简介

sphinx一个全文检索引擎。具有以下特点：  
- 索引和性能优异  
- 易于集成SQL和XML数据源，并可使用SphinxAPI、SphinxQL或者SphinxSE搜索接口  
- 易于通过分布式搜索进行扩展  
- 高速的索引建立(在当代CPU上，峰值性能可达到10 ~ 15MB/秒)  
- 高性能的搜索 (在1.2G文本，100万条文档上进行搜索，支持高达每秒150~250次查询)  

工作原理：Sphinx的整个工作流程就是Indexer程序到数据库里面提取数据，对数据进行分词，然后根据生成的分词生成单个或多个索引，并将它们传递给searchd程序。然后客户端可以通过API调用进行搜索。  

#### __sphinx__ 安装使用   
sphinx安装使用相对而言比较简单，具体可以参考[sphinx入门指南](http://www.sphinxsearch.org/archives/80)   

> sphinx 索引建立相关  

sphinx使用配置文件从数据库独处数据之后，讲数据传递给indexer程序，然后indexer就会逐条读取记录，根据粉刺泛对每条记录建立索引，分词算法可以是一元分词/mmseg分词。
>> * 倒排索引  
倒排索引是一种数据结构，用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。是文档检索系统中最常用的数据结构。  
倒排索引：是实现‘单词-文档矩阵’的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。  
传统的索引：索引ID->文档内容，而倒排索引是：文档内容->索引ID。  
倒排索引主要由两个部分组成：‘单词词典’和‘倒排文件’。  
单词词典是倒排缩影中非常重要的组成部分，用来维护文档集合中出现过的所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。在支持搜索时，根据用户的查询词，去单词词典里查询，就能获得相应的倒排列表，并以此作为后续排序的基础。  

>>> 倒排索引基础知识：
+ 文档（document）：一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象，相比网页来说，涵盖更多种的形式，比如word，pdf，xml等不同格式的文件都可以称之为文档。
* 文档集合（document collection）：由若干文档构成的集合称之为文档集合。  
* 文档编号 （document ID）：在搜索引擎内部，会将文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识。这样方便内部处理。
* 单词编号（word ID）：与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。  

indexer程序，就是根据配置好的分词算法，将获取到的记录进行分词，然后用倒排索引将数据结构保存起来。

>>> 分词算法  
+ 一元分词  
  原声的sphinx支持的分词算法就是一元分词，这种分词算法是对记录的每个词切割后做索引，这种缩影的优点就是覆盖率高，保证每个记录都能被搜索到。缺点就是会生成很大的索引文件，跟新索引时会消耗很多资源。
+ mmseg分词  
mmseg分词算法是基于统计模型的，所以算法的规则也是来自对语料库的分析和数学归纳，因为中文字符没有明确的分界，会导致大量的字符分界歧义，而且，中文里面，词和短语也很难界定，因此，算法除了要做统计和数学归纳之外，还要做歧义的解决。   
在mmseg分词中，有一个叫chunk的概念。   
chunk，是一句话的分词方式。包括一个词条数组和四个规则。  
如：研究生命，有“研究/生命”和“研究生/命”两种分词方式，这就是两个chunk。   
一个chunk有四个属性：长度、平均长度（长度/分词数）、方差、单字自由度（各单词条词频的对数之和）。   
做好分词之后，会得到多种分词方式，这时候就要使用一些过滤规则来完成歧义的解决，以得到最终的分词方式。    
歧义解决规则:   
1. 最大匹配 匹配最大长度的词。如“国际化”，有“国际/化”、“国际化”两种分词方式，选择后者  
2. 最大平均词长度 匹配平均词最大的chunk。如“南京市长江大桥”，有“南京市/长江大桥”、“南京/市长/江大桥”三种分词方式，前者平均词长度是7/2=3.5，后者是7/3=2.3，故选择前者的分词方式。  
3. 最大方差 去方差最大的chunk。如“研究生命科学”，有“研究生/命/科学”、“研究/生命/科学“两种分词方式，而它们的词长都一样是2。所以需要继续过滤，前者方差是0.82，后者方差是0。所以选择第一种分词方式。  
4. 最大单字自由度 选择单个字出现最高频率的chunk。比如”主要是因为“，有”主要/是/因为“，”主/要是/因为“两种分词方式，它们的词长、方差都一样，而”是“的词频较高，所以选择第一种分词方式。  
如果经过上述四个规则的过滤，剩下的chunk仍然大于一，那这个算法也无能为力了，只能自己写扩展完成。  


参考原文地址[sphinx中文入门指南](http://blog.jobbole.com/101672/)
